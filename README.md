# DLML_TextToTurtleBot

Der Turtlebot4 ist eine autonom fahrende Plattform, die über eine Python API programmiert werden kann. Man kann bspw. angeben, dass er zu einer Koordinate im Raum oder zur Dockingstation fahren soll. In dieser Arbeit sollen die Befehle per Text angegeben werden, bspw. "Fahre zu Punkt (4, 5)" oder "Fahre zu Docking Station", wobei ein Large Language Model (LMM) aus dem Text den entsprechenden Befehl erzeugen muss. Diese Funktionalität wird im Tutorial am Ende der Webseite beschrieben: turtlebot.github.io/turtlebot4-user-manual/tutorials/turtlebot4_navigator.html basiert auf: code-as-policies.github.io Diese Arbeit könnte noch dahingehend erweitert werden, dass anstelle der OpenAI API ein Open Source LLM genutzt wird. Außerdem sollen auch Befehle wie "Fahre zur Tür" umgesetzt werden können. Wenn der Roboter noch nicht weiß wo sich die Tür befindet, soll er diese durch zufälliges herumfahren suchen. Eine Kamera ist an dem Turtlebot angebracht, die für eine Objektdetektion genutzt werden kann. Hierbei sollte ein Open-Vocabulary Objekt Detektionsmodell wie bspw. docs.ultralytics.com/models/yolo-world genutzt werden. Ähnliche Arbeit: github.com/aniskoubaa/rosgpt github.com/bilel-bj/ROSGPT_Vision Farooq, M. U., Kang, G., Seo, J., Bae, J., Kang, S., & Jang, Y. J. (2024, May). DAIM-HRI: A new Human-Robot Integration Technology for Industries. In 2024 IEEE International Conference on Advanced Robotics and Its Social Impacts (ARSO) (pp. 7-12). IEEE. github.com/nasa-jpl/rosa
