{
  "default_provider": "openai",
  "max_iterations": 40,
  "adapters": {
    "ollama": {
      "model": "llama3",
      "temperature": 0.1,
      "options": {
        "base_url": "http://localhost:11434"
      }
    },
    "openai": {
      "model": "gpt-5-mini",
      "temperature": 0.1,
      "max_iterations": 60,
      "options": {
        "organization": "org-fRH94Fz4AYPn76fYf3pJ79k1"
      }
    },
    "gemini": {
      "model": "gemini-2.5-flash",
      "temperature": 0.1,
      "options": {}
    }
  }
}
